# -*- coding: utf-8 -*-
"""Agregacoes_Tarefa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LFocR8a0ce0K2K4iA0SH5Yn_i1-RV7qE
"""

from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.window import Window

# Inicializar SparkSession
spark = SparkSession.builder \
    .appName("VideoAnalysis") \
    .getOrCreate()

# Definir caminho completo
caminho_arquivo = "/content/drive/MyDrive/Data Apoio/Tarefa_agg_Avan/videos-preparados.snappy.parquet"

# 1. Ler o arquivo parquet
df_video = spark.read.parquet("/content/drive/MyDrive/Data Apoio/Tarefa_agg_Avan/videos-preparados.snappy.parquet")

# 2. Quantidade de registros por Keyword
count_by_keyword = df_video.groupBy("Keyword").count().orderBy("Keyword")

# 3. Média de Interaction por Keyword
avg_interaction = df_video.groupBy("Keyword") \
    .agg(F.mean("Interaction").alias("Avg Interaction")) \
    .orderBy("Keyword")

# 4. Máximo de Interaction por Keyword (Rank Interactions)
max_interaction = df_video.groupBy("Keyword") \
    .agg(F.max("Interaction").alias("Rank Interactions")) \
    .orderBy(F.col("Rank Interactions").desc())

# 5. Média e variância de Views por Keyword
views_stats = df_video.groupBy("Keyword") \
    .agg(
        F.mean("Views").alias("Avg Views"),
        F.variance("Views").alias("Variance Views")
    ).orderBy("Keyword")

# 6. Média, min e max de Views (sem decimais)
views_min_max = df_video.groupBy("Keyword") \
    .agg(
        F.round(F.mean("Views"), 0).alias("Avg Views"),
        F.min("Views").alias("Min Views"),
        F.max("Views").alias("Max Views")
    ).orderBy("Keyword")

# 7. Primeiro e último Published At por Keyword
published_dates = df_video.groupBy("Keyword") \
    .agg(
        F.min("Published At").alias("First Published"),
        F.max("Published At").alias("Last Published")
    ).orderBy("Keyword")

# 8. Contagem total e única de títulos
title_counts = df_video.agg(
    F.count("title").alias("Total Titles"),
    F.countDistinct("title").alias("Unique Titles")
)

# 9. Quantidade de registros por ano (ascendente)
df_video_with_year = df_video.withColumn("Year", F.year("Published At"))
count_by_year = df_video_with_year.groupBy("Year").count().orderBy("Year")

# 10. Quantidade de registros por ano e mês (ascendente)
df_video_with_ym = df_video_with_year.withColumn("Month", F.month("Published At"))
count_by_year_month = df_video_with_ym.groupBy("Year", "Month").count().orderBy("Year", "Month")

# 11. Média acumulativa de Likes por Keyword ao longo dos anos
window_spec = Window.partitionBy("Keyword").orderBy("Year").rowsBetween(Window.unboundedPreceding, Window.currentRow)

cumulative_avg_likes = df_video_with_year.groupBy("Keyword", "Year") \
    .agg(F.mean("Likes").alias("Yearly Avg Likes")) \
    .withColumn("Cumulative Avg Likes", F.mean("Yearly Avg Likes").over(window_spec)) \
    .orderBy("Keyword", "Year")

# Exibir resultados (opcional - para visualização)
print("=== Quantidade por Keyword ===")
count_by_keyword.show()

print("\n=== Média de Interaction ===")
avg_interaction.show()

print("\n=== Rank Interactions ===")
max_interaction.show()

print("\n=== Estatísticas de Views ===")
views_stats.show()

print("\n=== Min/Max de Views ===")
views_min_max.show()

print("\n=== Datas de Publicação ===")
published_dates.show()

print("\n=== Contagem de Títulos ===")
title_counts.show()

print("\n=== Registros por Ano ===")
count_by_year.show()

print("\n=== Registros por Ano/Mês ===")
count_by_year_month.show()

print("\n=== Média Acumulativa de Likes ===")
cumulative_avg_likes.show()

# Encerrar sessão Spark
spark.stop()